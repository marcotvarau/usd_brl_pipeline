# ğŸš€ USD/BRL Machine Learning Pipeline

[![Python Version](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Code Style](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Documentation](https://img.shields.io/badge/docs-available-brightgreen.svg)](docs/)

Sistema completo de coleta, processamento e estruturaÃ§Ã£o de dados para prediÃ§Ã£o da taxa de cÃ¢mbio USD/BRL usando machine learning. Pipeline de produÃ§Ã£o com coleta automÃ¡tica de dados brasileiros e internacionais, feature engineering avanÃ§ado e validaÃ§Ã£o rigorosa.

## ğŸ“‹ Ãndice

- [CaracterÃ­sticas](#-caracterÃ­sticas)
- [Arquitetura](#-arquitetura)
- [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [ConfiguraÃ§Ã£o](#-configuraÃ§Ã£o)
- [Uso](#-uso)
- [Estrutura de Dados](#-estrutura-de-dados)
- [API Documentation](#-api-documentation)
- [Desenvolvimento](#-desenvolvimento)
- [Troubleshooting](#-troubleshooting)
- [Contribuindo](#-contribuindo)

## âœ¨ CaracterÃ­sticas

### ğŸ“Š Coleta de Dados
- **Fontes Brasileiras Oficiais**:
  - Banco Central do Brasil (BCB): PTAX, SELIC, Focus
  - IBGE: IPCA, indicadores econÃ´micos
  - B3: Dados de mercado

- **Fontes Internacionais**:
  - Federal Reserve (FRED): Fed Funds, inflaÃ§Ã£o US, GDP
  - Yahoo Finance: Commodities, Ã­ndices, moedas
  - COT Reports: Posicionamento institucional

### ğŸ”§ Feature Engineering
- **150+ features** organizadas em 4 tiers por importÃ¢ncia preditiva
- Indicadores econÃ´micos customizados (diferencial de juros real, carry trade)
- Ãndice de commodities ponderado por exportaÃ§Ãµes brasileiras
- Indicadores tÃ©cnicos otimizados para forex
- Features temporais e sazonalidade brasileira

### âœ… Qualidade e Confiabilidade
- ValidaÃ§Ã£o automÃ¡tica com Great Expectations
- DetecÃ§Ã£o de data drift e anomalias
- Circuit breaker para proteÃ§Ã£o contra falhas de API
- Cache Redis com fallback local
- Logging estruturado em JSON

### ğŸš€ Performance e Escalabilidade
- Processamento paralelo de mÃºltiplas fontes
- Chunked processing para grandes volumes
- CompressÃ£o automÃ¡tica de dados
- Suporte a mÃºltiplos formatos (CSV, Parquet, HDF5)

## ğŸ— Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Data Sources Layer                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   BCB API       â”‚   FRED API      â”‚   Yahoo Finance            â”‚
â”‚   (PTAX, SELIC) â”‚   (Fed, CPI)    â”‚   (DXY, Commodities)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Collection Layer                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  BCBCollectorâ”‚  â”‚ FREDCollectorâ”‚  â”‚YahooCollectorâ”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                    Circuit Breaker + Retry Logic                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Processing Layer                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚DataCleaner   â”‚  â”‚FeatureEngineerâ”‚ â”‚TechnicalCalc â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Validation Layer                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚QualityValidatorâ”‚ â”‚DriftMonitor  â”‚  â”‚IntegrityCheckâ”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Output Layer                               â”‚
â”‚     CSV / Parquet / HDF5 / PostgreSQL / MongoDB                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ’» InstalaÃ§Ã£o

### PrÃ©-requisitos
- Python 3.8+
- Redis (opcional, para cache distribuÃ­do)
- PostgreSQL (opcional, para armazenamento)

### InstalaÃ§Ã£o RÃ¡pida

```bash
# Clone o repositÃ³rio
git clone https://github.com/seu-usuario/usd-brl-pipeline.git
cd usd-brl-pipeline

# Crie ambiente virtual
python -m venv venv
source venv/bin/activate  # No Windows: venv\Scripts\activate

# Instale dependÃªncias
pip install -r requirements.txt

# Configure variÃ¡veis de ambiente
cp .env.example .env
# Edite .env com suas credenciais de API
```

### InstalaÃ§Ã£o com Docker

```bash
# Build da imagem
docker build -t usd-brl-pipeline .

# Execute o container
docker run -d \
  --name usd-brl-pipeline \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/logs:/app/logs \
  --env-file .env \
  usd-brl-pipeline
```

## âš™ï¸ ConfiguraÃ§Ã£o

### Credenciais de API

Edite o arquivo `.env`:

```bash
# Federal Reserve Economic Data
FRED_API_KEY=your_fred_api_key_here

# Alpha Vantage (opcional)
ALPHA_VANTAGE_API_KEY=your_alpha_vantage_key

# Database
DB_HOST=localhost
DB_PORT=5432
DB_USER=postgres
DB_PASSWORD=your_password
DB_NAME=usd_brl_pipeline

# Redis Cache
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

# Email Notifications
SMTP_SERVER=smtp.gmail.com
SMTP_PORT=587
EMAIL_SENDER=your_email@gmail.com
EMAIL_PASSWORD=your_app_password
EMAIL_RECIPIENT=recipient@example.com
```

### ConfiguraÃ§Ã£o do Pipeline

Edite `config.yaml` para customizar:

```yaml
collection:
  start_date: "2014-01-01"  # Data inicial
  frequency: "daily"         # FrequÃªncia de coleta
  cache_ttl_hours: 1        # TTL do cache

features:
  lag_periods: [1, 2, 5, 10, 22, 44, 66]
  rolling_windows: [5, 10, 22, 44, 66]
  
validation:
  max_missing_pct: 5.0      # MÃ¡ximo de dados faltantes
  ranges:
    usd_brl:
      min: 1.0
      max: 10.0
```

## ğŸš€ Uso

### ExecuÃ§Ã£o BÃ¡sica

```bash
# Executar pipeline completo (Ãºltimos 5 dias)
python scripts/run_pipeline.py

# Executar para perÃ­odo especÃ­fico
python scripts/run_pipeline.py --start-date 2023-01-01 --end-date 2023-12-31

# Executar apenas coletores especÃ­ficos
python scripts/run_pipeline.py --collectors bcb yahoo fred

# ForÃ§ar atualizaÃ§Ã£o ignorando cache
python scripts/run_pipeline.py --force-refresh
```

### Modos de ExecuÃ§Ã£o

```bash
# Modo backfill (dados histÃ³ricos)
python scripts/run_pipeline.py --mode backfill --start-date 2014-01-01

# Modo validaÃ§Ã£o (verificar qualidade)
python scripts/run_pipeline.py --mode validate

# Modo repair (corrigir problemas)
python scripts/run_pipeline.py --mode repair

# Modo dry-run (teste sem exportar)
python scripts/run_pipeline.py --dry-run
```

### Agendamento AutomÃ¡tico

```bash
# Adicionar ao crontab para execuÃ§Ã£o diÃ¡ria Ã s 19h
0 19 * * * /path/to/venv/bin/python /path/to/run_pipeline.py --mode daily

# Ou usar o scheduler interno
python scripts/scheduler.py
```

### Uso ProgramÃ¡tico

```python
from src.pipeline.orchestrator import PipelineOrchestrator

# Inicializar pipeline
orchestrator = PipelineOrchestrator('config.yaml')

# Executar coleta
results = orchestrator.run_pipeline(
    start_date='2023-01-01',
    end_date='2023-12-31',
    collectors=['bcb', 'fred', 'yahoo']
)

# Acessar dados
data = results['data']
print(f"Shape: {data.shape}")
print(f"Features: {data.columns.tolist()}")
print(f"Date range: {data.index.min()} to {data.index.max()}")
```

## ğŸ“Š Estrutura de Dados

### Features por Tier

#### Tier 1 (40% poder preditivo)
- `usd_brl_ptax_close`: Taxa PTAX oficial
- `selic_rate`: Taxa SELIC
- `fed_funds_rate`: Fed Funds Rate
- `dxy_index`: US Dollar Index
- `real_interest_differential`: Diferencial de juros real
- `usd_brl_implied_volatility`: Volatilidade implÃ­cita

#### Tier 2 (30% poder preditivo)
- `brazilian_commodity_index`: Ãndice customizado de commodities
- `ipca_monthly_yoy`: InflaÃ§Ã£o brasileira
- `us_cpi_yoy`: InflaÃ§Ã£o americana
- `capital_flows_net`: Fluxo lÃ­quido de capital
- `brazil_fiscal_balance`: BalanÃ§o fiscal

#### Tier 3 (20% poder preditivo)
- `risk_sentiment_score`: Score de sentimento de risco
- `carry_trade_attractiveness`: Atratividade do carry trade
- `cot_sentiment_aggregate`: Sentiment COT agregado
- `correlation_emerging_markets`: CorrelaÃ§Ã£o com emergentes

#### Tier 4 (10% poder preditivo)
- Indicadores tÃ©cnicos (RSI, MACD, Bollinger Bands)
- Features temporais e sazonais
- PadrÃµes de preÃ§o

### Exemplo de Dataset

```csv
date,usd_brl_ptax_close,selic_rate,fed_funds_rate,real_interest_differential,risk_sentiment_score
2023-01-02,5.2194,13.75,4.33,8.21,42.1
2023-01-03,5.2567,13.75,4.33,8.18,43.8
2023-01-04,5.2145,13.75,4.33,8.19,41.9
```

## ğŸ“– API Documentation

### Collectors

```python
# BCB Collector
from src.collectors.bcb_collector import BCBCollector

collector = BCBCollector(config)
data = collector.collect(
    start_date='2023-01-01',
    end_date='2023-12-31',
    series=['selic_daily', 'ipca_monthly']
)
```

### Feature Engineering

```python
from src.processors.feature_engineer import FeatureEngineer

engineer = FeatureEngineer(config)
features = engineer.engineer_all_features(raw_data)

# Features especÃ­ficas
interest_diff = engineer.create_interest_rate_features(data)
commodity_index = engineer.create_commodity_index(data)
risk_score = engineer.create_risk_sentiment_score(data)
```

### Validation

```python
from src.validators.quality_validator import QualityValidator

validator = QualityValidator(config)
results = validator.validate(data)

if not results['passed']:
    print(f"Validation issues: {results['issues']}")
```

## ğŸ§ª Testes

```bash
# Executar todos os testes
pytest

# Testes com coverage
pytest --cov=src --cov-report=html

# Testes especÃ­ficos
pytest tests/test_collectors.py
pytest tests/test_feature_engineering.py

# Testes de integraÃ§Ã£o
pytest tests/integration/ --slow
```

## ğŸ›  Desenvolvimento

### Estrutura do Projeto

```
usd_brl_pipeline/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ collectors/       # Coletores de dados
â”‚   â”œâ”€â”€ processors/       # Processamento e features
â”‚   â”œâ”€â”€ validators/       # ValidaÃ§Ã£o de qualidade
â”‚   â”œâ”€â”€ exporters/        # ExportaÃ§Ã£o de dados
â”‚   â”œâ”€â”€ utils/           # UtilitÃ¡rios
â”‚   â””â”€â”€ pipeline/        # OrquestraÃ§Ã£o
â”œâ”€â”€ tests/               # Testes unitÃ¡rios
â”œâ”€â”€ scripts/             # Scripts de execuÃ§Ã£o
â”œâ”€â”€ notebooks/           # AnÃ¡lise exploratÃ³ria
â”œâ”€â”€ data/               # Dados (git-ignored)
â”œâ”€â”€ logs/               # Logs (git-ignored)
â””â”€â”€ docs/               # DocumentaÃ§Ã£o
```

### Adicionando Novos Coletores

1. Crie uma classe herdando de `BaseCollector`
2. Implemente os mÃ©todos `collect()` e `validate_data()`
3. Adicione ao orchestrator
4. Escreva testes

Exemplo:

```python
from src.collectors.base_collector import BaseCollector

class MyCollector(BaseCollector):
    def _initialize(self):
        # Setup especÃ­fico
        pass
    
    def collect(self, start_date, end_date):
        # Implementar coleta
        pass
    
    def validate_data(self, data):
        # Implementar validaÃ§Ã£o
        pass
```

## ğŸ› Troubleshooting

### Problemas Comuns

#### Erro de API Key
```
Error: FRED API key not found
Solution: Configure FRED_API_KEY in .env file
```

#### Dados faltantes
```
Warning: Excessive missing data
Solution: Check API availability, extend date range, or use --force-refresh
```

#### MemÃ³ria insuficiente
```
MemoryError during processing
Solution: Reduce chunk_size in config.yaml or process smaller date ranges
```

### Logs

Verifique os logs para diagnÃ³stico:

```bash
# Log principal
tail -f logs/pipeline.log

# Apenas erros
tail -f logs/errors.log

# ValidaÃ§Ã£o
tail -f logs/validation.log
```

## ğŸ“ˆ Performance

### Benchmarks

- **Coleta de dados**: ~2-5 min para 1 ano de dados
- **Feature engineering**: ~30s para 10.000 linhas
- **ValidaÃ§Ã£o completa**: ~10s para dataset completo
- **Export CSV**: ~5s para 100MB

### OtimizaÃ§Ãµes

- Use cache Redis para ambientes distribuÃ­dos
- Configure `chunk_size` baseado na memÃ³ria disponÃ­vel
- Use Parquet para datasets grandes
- Habilite compressÃ£o para reduzir I/O

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. Fork o projeto
2. Crie sua feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

### Guidelines

- Siga PEP 8 e use Black para formataÃ§Ã£o
- Adicione testes para novas funcionalidades
- Atualize a documentaÃ§Ã£o
- Mantenha compatibilidade com Python 3.8+

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ™ Agradecimentos

- Banco Central do Brasil pela API pÃºblica
- Federal Reserve pelo FRED API
- Comunidade Python pelos excelentes pacotes
- Contribuidores do projeto

## ğŸ“¬ Contato

Para questÃµes, sugestÃµes ou suporte:

- Issues: [GitHub Issues](https://github.com/seu-usuario/usd-brl-pipeline/issues)
- Email: seu-email@example.com

---

**Desenvolvido com â¤ï¸ para a comunidade de Data Science brasileira**